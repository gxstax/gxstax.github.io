{"meta":{"title":"马以的博客","subtitle":"","description":"","author":"马以","url":"https://gxstax.github.io","root":"/"},"pages":[{"title":"云原生","date":"2022-02-28T02:39:25.000Z","updated":"2022-02-28T02:40:50.504Z","comments":true,"path":"云原生/index.html","permalink":"https://gxstax.github.io/%E4%BA%91%E5%8E%9F%E7%94%9F/index.html","excerpt":"","text":""},{"title":"categories","date":"2022-02-28T02:43:34.000Z","updated":"2022-02-28T02:50:00.845Z","comments":true,"path":"categories/index.html","permalink":"https://gxstax.github.io/categories/index.html","excerpt":"","text":""},{"title":"tags","date":"2022-02-28T03:04:09.000Z","updated":"2022-02-28T03:23:09.148Z","comments":true,"path":"tags/index.html","permalink":"https://gxstax.github.io/tags/index.html","excerpt":"","text":""},{"title":"操作系统","date":"2022-02-28T02:59:32.000Z","updated":"2022-02-28T03:00:17.477Z","comments":true,"path":"操作系统/index.html","permalink":"https://gxstax.github.io/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/index.html","excerpt":"","text":""},{"title":"repository","date":"2022-02-28T03:28:39.000Z","updated":"2022-02-28T03:46:33.808Z","comments":false,"path":"repository/index.html","permalink":"https://gxstax.github.io/repository/index.html","excerpt":"","text":""},{"title":"links","date":"2022-02-28T03:33:28.000Z","updated":"2022-02-28T03:34:23.283Z","comments":false,"path":"links/index.html","permalink":"https://gxstax.github.io/links/index.html","excerpt":"","text":""},{"title":"about","date":"2022-02-28T03:37:14.000Z","updated":"2022-02-28T03:37:51.965Z","comments":false,"path":"about/index.html","permalink":"https://gxstax.github.io/about/index.html","excerpt":"","text":""}],"posts":[{"title":"StatefulSet之存储状态","slug":"StatefulSet之存储状态","date":"2022-02-25T05:56:50.000Z","updated":"2022-02-28T03:25:51.390Z","comments":true,"path":"2022/02/25/StatefulSet之存储状态/","link":"","permalink":"https://gxstax.github.io/2022/02/25/StatefulSet%E4%B9%8B%E5%AD%98%E5%82%A8%E7%8A%B6%E6%80%81/","excerpt":"","text":"在上一篇文章中，我和你分享了 StatefulSet 如何保证应用实例的拓扑状态，在 Pod 删除和再创建的过程中保持稳定。 而在今天这篇文章中，我将继续为你解读 StatefulSet 对存储状态的管理机制。这个机制，主要使用的是一个叫作 Persistent Volume Claim 的功能。 在前面介绍 Pod 的时候，我曾提到过，要在一个 Pod 里声明 Volume，只要在 Pod 里加上 spec.volumes 字段即可。然后，你就可以在这个字段里定义一个具体类型的 Volume 了，比如：hostPath。 可是，你有没有想过这样一个场景：如果你并不知道有哪些 Volume 类型可以用，要怎么办呢？ 更具体地说，作为一个应用开发者，我可能对持久化存储项目（比如 Ceph、GlusterFS 等）一窍不通，也不知道公司的 Kubernetes 集群里到底是怎么搭建出来的，我也自然不会编写它们对应的 Volume 定义文件。 所谓“术业有专攻”，这些关于 Volume 的管理和远程持久化存储的知识，不仅超越了开发者的知识储备，还会有暴露公司基础设施秘密的风险。 比如，下面这个例子，就是一个声明了 Ceph RBD 类型 Volume 的 Pod： 1234567891011121314151617181920212223242526apiVersion: v1kind: Podmetadata: name: rbdspec: containers: - image: kubernetes/pause name: rbd-rw volumeMounts: - name: rbdpd mountPath: /mnt/rbd volumes: - name: rbdpd rbd: monitors: - &#x27;10.16.154.78:6789&#x27; - &#x27;10.16.154.82:6789&#x27; - &#x27;10.16.154.83:6789&#x27; pool: kube image: foo fsType: ext4 readOnly: true user: admin keyring: /etc/ceph/keyring imageformat: &quot;2&quot; imagefeatures: &quot;layering&quot; 其一，如果不懂得 Ceph RBD 的使用方法，那么这个 Pod 里 Volumes 字段，你十有八九也完全看不懂。其二，这个 Ceph RBD 对应的存储服务器的地址、用户名、授权文件的位置，也都被轻易地暴露给了全公司的所有开发人员，这是一个典型的信息被“过度暴露”的例子。 这也是为什么，在后来的演化中，Kubernetes 项目引入了一组叫作 Persistent Volume Claim（PVC）和 Persistent Volume（PV）的 API 对象，大大降低了用户声明和使用持久化 Volume 的门槛。 举个例子，有了 PVC 之后，一个开发人员想要使用一个 Volume，只需要简单的两步即可。 第一步：定义一个 PVC，声明想要的 Volume 的属性： 12345678910kind: PersistentVolumeClaimapiVersion: v1metadata: name: pv-claimspec: accessModes: - ReadWriteOnce resources: requests: storage: 1Gi 可以看到，在这个 PVC 对象里，不需要任何关于 Volume 细节的字段，只有描述性的属性和定义。比如，storage: 1Gi，表示我想要的 Volume 大小至少是 1 GiB；accessModes: ReadWriteOnce，表示这个 Volume 的挂载方式是可读写，并且只能被挂载在一个节点上而非被多个节点共享。 备注：关于哪种类型的 Volume 支持哪种类型的 AccessMode，你可以查看 Kubernetes 项目官方文档中的详细列表。 第二步：在应用的 Pod 中，声明使用这个 PVC： 123456789101112131415161718apiVersion: v1kind: Podmetadata: name: pv-podspec: containers: - name: pv-container image: nginx ports: - containerPort: 80 name: &quot;http-server&quot; volumeMounts: - mountPath: &quot;/usr/share/nginx/html&quot; name: pv-storage volumes: - name: pv-storage persistentVolumeClaim: claimName: pv-claim 可以看到，在这个 Pod 的 Volumes 定义中，我们只需要声明它的类型是 persistentVolumeClaim，然后指定 PVC 的名字，而完全不必关心 Volume 本身的定义。 这时候，只要我们创建这个 PVC 对象，Kubernetes 就会自动为它绑定一个符合条件的 Volume。可是，这些符合条件的 Volume 又是从哪里来的呢？ 答案是，它们来自于由运维人员维护的 PV（Persistent Volume）对象。接下来，我们一起看一个常见的 PV 对象的 YAML 文件： 1234567891011121314151617181920212223kind: PersistentVolumeapiVersion: v1metadata: name: pv-volume labels: type: localspec: capacity: storage: 10Gi accessModes: - ReadWriteOnce rbd: monitors: # 使用 kubectl get pods -n rook-ceph 查看 rook-ceph-mon- 开头的 POD IP 即可得下面的列表 - &#x27;10.16.154.78:6789&#x27; - &#x27;10.16.154.82:6789&#x27; - &#x27;10.16.154.83:6789&#x27; pool: kube image: foo fsType: ext4 readOnly: true user: admin keyring: /etc/ceph/keyring 可以看到，这个 PV 对象的 spec.rbd 字段，正是我们前面介绍过的 Ceph RBD Volume 的详细定义。而且，它还声明了这个 PV 的容量是 10 GiB。这样，Kubernetes 就会为我们刚刚创建的 PVC 对象绑定这个 PV。 所以，Kubernetes 中 PVC 和 PV 的设计，实际上类似于“接口”和“实现”的思想。开发者只要知道并会使用“接口”，即：PVC；而运维人员则负责给“接口”绑定具体的实现，即：PV。 这种解耦，就避免了因为向开发者暴露过多的存储系统细节而带来的隐患。此外，这种职责的分离，往往也意味着出现事故时可以更容易定位问题和明确责任，从而避免“扯皮”现象的出现。 我们还是以上一篇文章中用到的 StatefulSet 为例: 123456789101112131415161718192021222324252627282930313233apiVersion: apps/v1kind: StatefulSetmetadata: name: webspec: serviceName: &quot;nginx&quot; replicas: 2 selector: matchLabels: app: nginx template: metadata: labels: app: nginx spec: containers: - name: nginx image: nginx:1.9.1 ports: - containerPort: 80 name: web volumeMounts: - name: www mountPath: /usr/share/nginx/html volumeClaimTemplates: - metadata: name: www spec: accessModes: - ReadWriteOnce resources: requests: storage: 1Gi 这次，我们为这个 StatefulSet 额外添加了一个 volumeClaimTemplates 字段。从名字就可以看出来，它跟 Deployment 里 Pod 模板（PodTemplate）的作用类似。也就是说，凡是被这个 StatefulSet 管理的 Pod，都会声明一个对应的 PVC；而这个 PVC 的定义，就来自于 volumeClaimTemplates 这个模板字段。更重要的是，这个 PVC 的名字，会被分配一个与这个 Pod 完全一致的编号。 这个自动创建的 PVC，与 PV 绑定成功后，就会进入 Bound 状态，这就意味着这个 Pod 可以挂载并使用这个 PV 了。 如果你还是不太理解 PVC 的话，可以先记住这样一个结论：PVC 其实就是一种特殊的 Volume。只不过一个 PVC 具体是什么类型的 Volume，要在跟某个 PV 绑定之后才知道。关于 PV、PVC 更详细的知识，我会在容器存储部分做进一步解读。 当然，PVC 与 PV 的绑定得以实现的前提是，运维人员已经在系统里创建好了符合条件的 PV（比如，我们在前面用到的 pv-volume）；或者，你的 Kubernetes 集群运行在公有云上，这样 Kubernetes 就会通过 Dynamic Provisioning 的方式，自动为你创建与 PVC 匹配的 PV。 所以，我们在使用 kubectl create 创建了 StatefulSet 之后，就会看到 Kubernetes 集群里出现了两个 PVC： 12345$ kubectl create -f statefulset.yaml$ kubectl get pvc -l app=nginxNAME STATUS VOLUME CAPACITY ACCESSMODES AGEwww-web-0 Bound pvc-15c268c7-b507-11e6-932f-42010a800002 1Gi RWO 48swww-web-1 Bound pvc-15c79307-b507-11e6-932f-42010a800002 1Gi RWO 48s 可以看到，这些 PVC，都以“&lt; PVC名字 &gt;-&lt; StatefulSet 名字 &gt;-&lt; 编号 &gt;”的方式命名，并且处于 Bound 状态。 我们前面已经讲到过，这个 StatefulSet 创建出来的所有 Pod，都会声明使用编号的 PVC。比如，在名叫 web-0 的 Pod 的 volumes 字段，它会声明使用名叫 www-web-0 的 PVC，从而挂载到这个 PVC 所绑定的 PV。 所以，我们就可以使用如下所示的指令，在 Pod 的 Volume 目录里写入一个文件，来验证一下上述 Volume 的分配情况： 1$ for i in 0 1; do kubectl exec web-$i -- sh -c &#x27;echo hello $(hostname) &gt; /usr/share/nginx/html/index.html&#x27;; done 如上所示，通过 kubectl exec 指令，我们在每个 Pod 的 Volume 目录里，写入了一个 index.html 文件。这个文件的内容，正是 Pod 的 hostname。比如，我们在 web-0 的 index.html 里写入的内容就是”hello web-0”。 此时，如果你在这个 Pod 容器里访问“http://localhost”，你实际访问到的就是 Pod 里 Nginx 服务器进程，而它会为你返回 /usr/share/nginx/html/index.html 里的内容。这个操作的执行方法如下所示： 123$ for i in 0 1; do kubectl exec -it web-$i -- curl localhost; donehello web-0hello web-1 现在，关键来了。 如果你使用 kubectl delete 命令删除这两个 Pod，这些 Volume 里的文件会不会丢失呢？ 123$ kubectl delete pod -l app=nginxpod &quot;web-0&quot; deletedpod &quot;web-1&quot; deleted 可以看到，正如我们前面介绍过的，在被删除之后，这两个 Pod 会被按照编号的顺序被重新创建出来。而这时候，如果你在新创建的容器里通过访问“http://localhost”的方式去访问 web-0 里的 Nginx 服务： 123# 在被重新创建出来的Pod容器里访问http://localhost$ kubectl exec -it web-0 -- curl localhosthello web-0 就会发现，这个请求依然会返回：hello web-0。也就是说，原先与名叫 web-0 的 Pod 绑定的 PV，在这个 Pod 被重新创建之后，依然同新的名叫 web-0 的 Pod 绑定在了一起。对于 Pod web-1 来说，也是完全一样的情况。 这是怎么做到的呢？ 其实，我和你分析一下 StatefulSet 控制器恢复这个 Pod 的过程，你就可以很容易理解了。 首先，当你把一个 Pod，比如 web-0，删除之后，这个 Pod 对应的 PVC 和 PV，并不会被删除，而这个 Volume 里已经写入的数据，也依然会保存在远程存储服务里（比如，我们在这个例子里用到的 Ceph 服务器）。 此时，StatefulSet 控制器发现，一个名叫 web-0 的 Pod 消失了。所以，控制器就会重新创建一个新的、名字还是叫作 web-0 的 Pod 来，“纠正”这个不一致的情况。 需要注意的是，在这个新的 Pod 对象的定义里，它声明使用的 PVC 的名字，还是叫作：www-web-0。这个 PVC 的定义，还是来自于 PVC 模板（volumeClaimTemplates），这是 StatefulSet 创建 Pod 的标准流程。 所以，在这个新的 web-0 Pod 被创建出来之后，Kubernetes 为它查找名叫 www-web-0 的 PVC 时，就会直接找到旧 Pod 遗留下来的同名的 PVC，进而找到跟这个 PVC 绑定在一起的 PV。 这样，新的 Pod 就可以挂载到旧 Pod 对应的那个 Volume，并且获取到保存在 Volume 里的数据。 通过这种方式，Kubernetes 的 StatefulSet 就实现了对应用存储状态的管理。 看到这里，你是不是已经大致理解了 StatefulSet 的工作原理呢？现在，我再为你详细梳理一下吧。 首先，StatefulSet 的控制器直接管理的是 Pod。这是因为，StatefulSet 里的不同 Pod 实例，不再像 ReplicaSet 中那样都是完全一样的，而是有了细微区别的。比如，每个 Pod 的 hostname、名字等都是不同的、携带了编号的。而 StatefulSet 区分这些实例的方式，就是通过在 Pod 的名字里加上事先约定好的编号。 其次，Kubernetes 通过 Headless Service，为这些有编号的 Pod，在 DNS 服务器中生成带有同样编号的 DNS 记录。只要 StatefulSet 能够保证这些 Pod 名字里的编号不变，那么 Service 里类似于 web-0.nginx.default.svc.cluster.local 这样的 DNS 记录也就不会变，而这条记录解析出来的 Pod 的 IP 地址，则会随着后端 Pod 的删除和再创建而自动更新。这当然是 Service 机制本身的能力，不需要 StatefulSet 操心。 最后，StatefulSet 还为每一个 Pod 分配并创建一个同样编号的 PVC。这样，Kubernetes 就可以通过 Persistent Volume 机制为这个 PVC 绑定上对应的 PV，从而保证了每一个 Pod 都拥有一个独立的 Volume。 在这种情况下，即使 Pod 被删除，它所对应的 PVC 和 PV 依然会保留下来。所以当这个 Pod 被重新创建出来之后，Kubernetes 会为它找到同样编号的 PVC，挂载这个 PVC 对应的 Volume，从而获取到以前保存在 Volume 里的数据。 这么一看，原本非常复杂的 StatefulSet，是不是也很容易理解了呢？","categories":[{"name":"云原生","slug":"云原生","permalink":"https://gxstax.github.io/categories/%E4%BA%91%E5%8E%9F%E7%94%9F/"},{"name":"k8s","slug":"云原生/k8s","permalink":"https://gxstax.github.io/categories/%E4%BA%91%E5%8E%9F%E7%94%9F/k8s/"}],"tags":[{"name":"k8s","slug":"k8s","permalink":"https://gxstax.github.io/tags/k8s/"}]},{"title":"k8s-Headless Service","slug":"k8s-Headless-Service","date":"2022-02-25T03:09:54.000Z","updated":"2022-02-28T03:25:33.139Z","comments":true,"path":"2022/02/25/k8s-Headless-Service/","link":"","permalink":"https://gxstax.github.io/2022/02/25/k8s-Headless-Service/","excerpt":"","text":"如何保证应用实例的拓扑状态，在 Pod 删除和再创建的过程中保持稳定Kubernetes架构master节点有一个很重要的组件-Service，Service 是 Kubernetes 项目中用来将一组 Pod 暴露给外界访问的一种机制。比如，一个 Deployment 有 3 个 Pod，那么我就可以定义一个 Service。然后，用户只要能访问到这个 Service，它就能访问到某个具体的 Pod。 那么，这个 Service 又是如何被访问的呢？ 第一种方式，是以 Service 的 VIP（Virtual IP，即：虚拟 IP）方式。 比如：当我访问 10.0.23.1 这个 Service 的 IP 地址时，10.0.23.1 其实就是一个 VIP，它会把请求转发到该 Service 所代理的某一个 Pod 上。 第二种方式，就是以 Service 的 DNS 方式。 比如：这时候，只要我访问“my-svc.my-namespace.svc.cluster.local”这条 DNS 记录，就可以访问到名叫 my-svc 的 Service 所代理的某一个 Pod。 而在第二种 Service DNS 的方式下，具体还可以分为两种处理方法： 第一种处理方法，是 Normal Service。这种情况下，你访问“my-svc.my-namespace.svc.cluster.local”解析到的，正是 my-svc 这个 Service 的 VIP，后面的流程就跟 VIP 方式一致了。 而第二种处理方法，正是 Headless Service。这种情况下，你访问“my-svc.my-namespace.svc.cluster.local”解析到的，直接就是 my-svc 代理的某一个 Pod 的 IP 地址。可以看到，这里的区别在于，Headless Service 不需要分配一个 VIP，而是可以直接以 DNS 记录的方式解析出被代理 Pod 的 IP 地址。 那么，这样的设计又有什么作用呢？ 想要回答这个问题，我们需要从 Headless Service 的定义方式看起。 下面是一个标准的 Headless Service 对应的 YAML 文件： 12345678910111213apiVersion: v1kind: Servicemetadata: name: nginx labels: app: nginxspec: ports: - port: 80 name: web clusterIP: None selector: app: nginx 可以看到，所谓的 Headless Service，其实仍是一个标准 Service 的 YAML 文件。只不过，它的 clusterIP 字段的值是：None，即：这个 Service，没有一个 VIP 作为“头”。这也就是 Headless 的含义。所以，这个 Service 被创建后并不会被分配一个 VIP，而是会以 DNS 记录的方式暴露出它所代理的 Pod。 而它所代理的 Pod，依然是 Label Selector 机制选择出来的，即：所有携带了 app=nginx 标签的 Pod，都会被这个 Service 代理起来。 然后关键来了。当你按照这样的方式创建了一个 Headless Service 之后，它所代理的所有 Pod 的 IP 地址，都会被绑定一个这样格式的 DNS 记录，如下所示： 1&lt;pod-name&gt;.&lt;svc-name&gt;.&lt;namespace&gt;.svc.cluster.local 这个 DNS 记录，正是 Kubernetes 项目为 Pod 分配的唯一的“可解析身份”（Resolvable Identity）。 有了这个“可解析身份”，只要你知道了一个 Pod 的名字，以及它对应的 Service 的名字，你就可以非常确定地通过这条 DNS 记录访问到 Pod 的 IP 地址。 那么，StatefulSet 又是如何使用这个 DNS 记录来维持 Pod 的拓扑状态的呢？ 为了回答这个问题，现在我们就来编写一个 StatefulSet 的 YAML 文件，如下所示： 123456789101112131415161718192021apiVersion: apps/v1kind: StatefulSetmetadata: name: webspec: serviceName: &quot;nginx&quot; replicas: 2 selector: matchLabels: app: nginx template: metadata: labels: app: nginx spec: containers: - name: nginx image: nginx:1.9.1 ports: - containerPort: 80 name: web 这个 YAML 文件，和我们在前面文章中用到的 nginx-deployment 的唯一区别，就是多了一个 serviceName=nginx 字段。 这个字段的作用，就是告诉 StatefulSet 控制器，在执行控制循环（Control Loop）的时候，请使用 nginx 这个 Headless Service 来保证 Pod 的“可解析身份”。 所以，当你通过 kubectl create 创建了上面这个 Service 和 StatefulSet 之后，就会看到如下两个对象： 1234567891011$ kubectl create -f svc.yaml$ kubectl get service nginxNAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGEnginx ClusterIP None &lt;none&gt; 80/TCP 9s$ kubectl create -f statefulset.yaml$ kubectl get statefulset webNAME READY AGEweb 2/2 32sREADY 字段里面的字段表示的是 当前运行副本个数/期望运行个数 这时候，如果你手比较快的话，还可以通过 kubectl 的 -w 参数，即：Watch 功能，实时查看 StatefulSet 创建两个有状态实例的过程： 备注：如果手不够快的话，Pod 很快就创建完了。不过，你依然可以通过这个 StatefulSet 的 Events 看到这些信息。 1234$ kubectl get pods -w -l app=nginxNAME READY STATUS RESTARTS AGEweb-0 1/1 Running 0 3m21sweb-1 1/1 Running 0 3m8s 通过上面这个 Pod 的创建过程，我们不难看到，StatefulSet 给它所管理的所有 Pod 的名字，进行了编号，编号规则是 [statefulset name]-[ordinal index]。 而且这些编号都是从 0 开始累加，与 StatefulSet 的每个 Pod 实例一一对应，绝不重复。 更重要的是，这些 Pod 的创建，也是严格按照编号顺序进行的。比如，在 web-0 进入到 Running 状态、并且细分状态（Conditions）成为 Ready 之前，web-1 会一直处于 Pending 状态。 备注：Ready 状态再一次提醒了我们，为 Pod 设置 livenessProbe 和 readinessProbe 的重要性。 当这两个 Pod 都进入了 Running 状态之后，你就可以查看到它们各自唯一的“网络身份”了。 我们使用 kubectl exec 命令进入到容器中查看它们的 hostname： 1234$ kubectl exec web-0 -- sh -c &#x27;hostname&#x27;web-0$ kubectl exec web-1 -- sh -c &#x27;hostname&#x27;web-1 可以看到，这两个 Pod 的 hostname 与 Pod 名字是一致的，都被分配了对应的编号。接下来，我们再试着以 DNS 的方式，访问一下这个 Headless Service： 1$ kubectl run -i --tty --image busybox:1.28.4 dns-test --restart=Never --rm /bin/sh 通过这条命令，我们启动了一个一次性的 Pod，因为 –rm 意味着 Pod 退出后就会被删除掉。然后，在这个 Pod 的容器里面，我们尝试用 nslookup 命令，解析一下 Pod 对应的 Headless Service： 123456789101112131415$ kubectl run -i --tty --image busybox:1.28.4 dns-test --restart=Never --rm /bin/shIf you don&#x27;t see a command prompt, try pressing enter./ # nslookup web-0.nginxServer: 10.96.0.10Address 1: 10.96.0.10 kube-dns.kube-system.svc.cluster.localName: web-0.nginxAddress 1: 10.44.0.5 web-0.nginx.default.svc.cluster.local/ # nslookup web-1.nginxServer: 10.96.0.10Address 1: 10.96.0.10 kube-dns.kube-system.svc.cluster.localName: web-1.nginxAddress 1: 10.32.0.7 web-1.nginx.default.svc.cluster.local 我们可以看到，在这个 StatefulSet 中，这两个新 Pod 的“网络标识”（比如：web-0.nginx 和 web-1.nginx），再次解析到了正确的 IP 地址（比如：web-0 Pod 的 IP 地址 10.44.0.5）。 通过这种方法，Kubernetes 就成功地将 Pod 的拓扑状态（比如：哪个节点先启动，哪个节点后启动），按照 Pod 的“名字 + 编号”的方式固定了下来。此外，Kubernetes 还为每一个 Pod 提供了一个固定并且唯一的访问入口，即：这个 Pod 对应的 DNS 记录。 这些状态，在 StatefulSet 的整个生命周期里都会保持不变，绝不会因为对应 Pod 的删除或者重新创建而失效。 不过，相信你也已经注意到了，尽管 web-0.nginx 这条记录本身不会变，但它解析到的 Pod 的 IP 地址，并不是固定的。这就意味着，对于“有状态应用”实例的访问，你必须使用 DNS 记录或者 hostname 的方式，而绝不应该直接访问这些 Pod 的 IP 地址。","categories":[{"name":"云原生","slug":"云原生","permalink":"https://gxstax.github.io/categories/%E4%BA%91%E5%8E%9F%E7%94%9F/"},{"name":"k8s","slug":"云原生/k8s","permalink":"https://gxstax.github.io/categories/%E4%BA%91%E5%8E%9F%E7%94%9F/k8s/"}],"tags":[{"name":"k8s","slug":"k8s","permalink":"https://gxstax.github.io/tags/k8s/"}]},{"title":"rabbitmq","slug":"rabbitmq","date":"2022-02-23T08:00:43.000Z","updated":"2022-02-27T11:30:00.838Z","comments":true,"path":"2022/02/23/rabbitmq/","link":"","permalink":"https://gxstax.github.io/2022/02/23/rabbitmq/","excerpt":"","text":"","categories":[{"name":"middleware","slug":"middleware","permalink":"https://gxstax.github.io/categories/middleware/"}],"tags":[{"name":"middleware","slug":"middleware","permalink":"https://gxstax.github.io/tags/middleware/"}]},{"title":"k8s命令","slug":"k8s命令","date":"2022-02-22T10:37:25.000Z","updated":"2022-02-28T03:25:14.264Z","comments":true,"path":"2022/02/22/k8s命令/","link":"","permalink":"https://gxstax.github.io/2022/02/22/k8s%E5%91%BD%E4%BB%A4/","excerpt":"","text":"1. master节点 查看node节点加入命令 1$ kubeadm token create --print-join-command 查看创建节点日志 123$ kubectl describe pods -l app=$&#123;pod_name&#125; $ kubectl describe pod $&#123;pod_name&#125; -n $&#123;name_space&#125; 重启k8s集群 12345678910111213141516171819 master节点执行： $ kubectl drain k8s-node1 --delete-local-data --force --ignore-daemonsets $ kubectl delete node k8s-node1 在相应node节点执行： $ kubeadm reset $ rm -rf /var/lib/cni/ $HOME/.kube/config /etc/cni/net.d master节点执行：$ kubectl drain k8s-node2 --delete-local-data --force --ignore-daemonsets$ kubectl delete node k8s-node2在相应node节点执行: $ kubeadm reset $ rm -rf /var/lib/cni/ $HOME/.kube/config /etc/cni/net.d 删除master节点：$ kubectl drain k8s-master --delete-local-data --force --ignore-daemonsets$ kubectl delete node k8s-master$ kubeadm reset $ rm -rf /var/lib/cni/ $HOME/.kube/config /etc/cni/net.d 实时查看 Deployment 对象的状态变化 1$ kubectl rollout status deployment/$&#123;deployment_name&#125; 修改镜像信息信息 1$ kubectl set image deployment/nginx-deployment nginx=nginx:1.91 回滚上一版本 1$ kubectl rollout undo deployment/nginx-deployment 查看Deployment 变更对应的版本 1$ kubectl rollout history deployment/nginx-deployment 回滚到执行版本 1$ kubectl rollout undo deployment/nginx-deployment --to-revision=2 暂停滚动更新 1$ kubectl rollout pause deployment/nginx-deployment 因为我们每修改一次deployment，都会生成一个新的ReplicaSet对象，这样显得有些多余和浪费资源，所以，当我们需要修改deployment的时候，先暂时暂停滚动更新，等到我们一次性修改完成后，再重新恢复即可。 恢复滚动更新 1$ kubectl rollout resume deployment/nginx-deployment 2. node节点 重置节点 123$ kubeadm reset删除配置信息$ rm -rf /var/lib/cni/ $HOME/.kube/config /etc/cni/net.d","categories":[{"name":"云原生","slug":"云原生","permalink":"https://gxstax.github.io/categories/%E4%BA%91%E5%8E%9F%E7%94%9F/"},{"name":"k8s","slug":"云原生/k8s","permalink":"https://gxstax.github.io/categories/%E4%BA%91%E5%8E%9F%E7%94%9F/k8s/"}],"tags":[{"name":"k8s","slug":"k8s","permalink":"https://gxstax.github.io/tags/k8s/"}]},{"title":"解决k8s相关组件安装镜像无法拉取","slug":"解决k8s相关组件安装镜像无法拉取","date":"2022-02-18T15:30:26.000Z","updated":"2022-03-03T10:41:48.195Z","comments":true,"path":"2022/02/18/解决k8s相关组件安装镜像无法拉取/","link":"","permalink":"https://gxstax.github.io/2022/02/18/%E8%A7%A3%E5%86%B3k8s%E7%9B%B8%E5%85%B3%E7%BB%84%E4%BB%B6%E5%AE%89%E8%A3%85%E9%95%9C%E5%83%8F%E6%97%A0%E6%B3%95%E6%8B%89%E5%8F%96/","excerpt":"","text":"k8s 集群搭建过程相关组件安装 在k8s 集群搭建过程中，我们在安装rook存储组件 以及ingress相关组件时，因为要访问https://k8s.gcr.io 去拉取镜像，而在墙内我们时访问不了这个组件的； 所以，我们采用的办法是，从阿里云把相应的镜像版本拉取到本地，然后打tag为官方镜像名称，这样，在拉取镜像的时候就直接从本地拉取，而不用访问https://k8s.gcr.io 去拉取了； rook 镜像 注意这里的版本要和具体报错的拉取镜像失败的版本一致，相关日志请用命令： 1$ kubectl describe pod $&#123;pod_name&#125; -n rook-ceph 查看； 123456789101112131415161718192021$ docker pull registry.aliyuncs.com/google_containers/csi-node-driver-registrar:v2.5.0$ docker tag registry.aliyuncs.com/google_containers/csi-node-driver-registrar:v2.5.0 k8s.gcr.io/sig-storage/csi-node-driver-registrar:v2.5.0$ docker rmi registry.aliyuncs.com/google_containers/csi-node-driver-registrar:v2.5.0$ docker pull registry.aliyuncs.com/google_containers/csi-provisioner:v3.1.0$ docker tag registry.aliyuncs.com/google_containers/csi-provisioner:v3.1.0 k8s.gcr.io/sig-storage/csi-provisioner:v3.1.0$ docker rmi registry.aliyuncs.com/google_containers/csi-provisioner:v3.1.0$ docker pull registry.aliyuncs.com/google_containers/csi-resizer:v1.4.0$ docker tag registry.aliyuncs.com/google_containers/csi-resizer:v1.4.0 k8s.gcr.io/sig-storage/csi-resizer:v1.4.0$ docker rmi registry.aliyuncs.com/google_containers/csi-resizer:v1.4.0$ docker pull registry.aliyuncs.com/google_containers/csi-attacher:v3.4.0$ docker tag registry.aliyuncs.com/google_containers/csi-attacher:v3.4.0 k8s.gcr.io/sig-storage/csi-attacher:v3.4.0$ docker rmi registry.aliyuncs.com/google_containers/csi-attacher:v3.4.0$ docker pull registry.aliyuncs.com/google_containers/csi-snapshotter:v5.0.1$ docker tag registry.aliyuncs.com/google_containers/csi-snapshotter:v5.0.1 k8s.gcr.io/sig-storage/csi-snapshotter:v5.0.1$ docker rmi registry.aliyuncs.com/google_containers/csi-snapshotter:v5.0.1 Ingress 镜像（版本获取同rook） 1234567$ docker pull registry.aliyuncs.com/google_containers/nginx-ingress-controller:v1.0.0$ docker tag registry.aliyuncs.com/google_containers/nginx-ingress-controller:v1.0.0 k8s.gcr.io/ingress-nginx/controller:v1.0.0$ docker rmi registry.aliyuncs.com/google_containers/nginx-ingress-controller:v1.0.0$ docker pull registry.aliyuncs.com/google_containers/kube-webhook-certgen:v1.0$ docker tag registry.aliyuncs.com/google_containers/kube-webhook-certgen:v1.0 k8s.gcr.io/ingress-nginx/kube-webhook-certgen:v1.0$ docker rmi registry.aliyuncs.com/google_containers/kube-webhook-certgen:v1.0 fluentd-elasticsearch 123$ docker pull registry.aliyuncs.com/google_containers/fluentd-elasticsearch:1.20$ docker tag registry.aliyuncs.com/google_containers/fluentd-elasticsearch:1.20 k8s.gcr.io/fluentd-elasticsearch:1.20$ docker rmi registry.aliyuncs.com/google_containers/fluentd-elasticsearch:1.20 注意 : 上面的命令在每个节点都要执行（比如我的环境 k8s-master、k8s-node1、k8s-node2）","categories":[{"name":"云原生","slug":"云原生","permalink":"https://gxstax.github.io/categories/%E4%BA%91%E5%8E%9F%E7%94%9F/"},{"name":"k8s","slug":"云原生/k8s","permalink":"https://gxstax.github.io/categories/%E4%BA%91%E5%8E%9F%E7%94%9F/k8s/"}],"tags":[{"name":"k8s","slug":"k8s","permalink":"https://gxstax.github.io/tags/k8s/"}]},{"title":"缓存数据库数据一致性保证演进过程","slug":"缓存数据库数据一致性保证演进过程","date":"2021-12-23T11:17:10.000Z","updated":"2022-02-27T11:30:00.838Z","comments":true,"path":"2021/12/23/缓存数据库数据一致性保证演进过程/","link":"","permalink":"https://gxstax.github.io/2021/12/23/%E7%BC%93%E5%AD%98%E6%95%B0%E6%8D%AE%E5%BA%93%E6%95%B0%E6%8D%AE%E4%B8%80%E8%87%B4%E6%80%A7%E4%BF%9D%E8%AF%81%E6%BC%94%E8%BF%9B%E8%BF%87%E7%A8%8B/","excerpt":"","text":"DTC 解决的业务痛点 1. 缓存数据库一致性问题 传统解决方案 全量数据刷新缓存 数据库的数据,全量刷入缓存（不设置失效时间）。 写请求只更新数据库，不更新缓存。 启动一个定时任务，定时把数据库的数据，更新到缓存中。 优点: 读请求可以直接命中缓存，不需查库，所以性能高。 缺点: 缓存利用率低: 不经常使用的数据还一直留在缓存中，全量数据，耗费缓存空间; 数据不一致: 定时刷新缓存，缓存中数据的更新节点完全依赖于定时任务频率和执行效率。 优化缓存利用率低和一致性 写请求只写数据库 读请求先读缓存，如果缓存不存在，则从数据库读取，并更新缓存。 同时，写入缓存的数据，都设置失效时间。 优点: 缓存中设置了过期时间，这样，缓存中保存的都是热点数据，解决了缓存利用率问题. 缺点: 异常引发数据不一致问题（这里分两种情况讨论）: ① 「先更新缓存，后更新数据库」 如果缓存更新成功了，但数据库更新失败，那么此时缓存中是最新值，但数据库是「旧值」。 虽然此时读请求可以命中缓存，拿到正确的值，但是一旦「缓存失效」。 就会从数据库中读取「旧值」， 这时更新进缓存的也是这个旧值。 这时，用户就会发现之前修改过的数据，突然又「变回去」了。 ② 「先更新数据库，后更新缓存」 数据库更新成功，写缓存失败，那么数据库是最新值，缓存中是「旧值」。 这时用户从缓存中读到的全是旧数据，直到「缓存失效」后，读数据库才能读到最新的值。 这时用户发现，自己修改的值，迟迟不能生效。 并发引发数据不一致问题: ① 「先更新缓存，后更新数据库」 接下来我们看，即使数据库和缓存都更新成功，会不会就没什么问题了？ 假设现在又线程 A 和线程 B 两个线程，需要更新「同一条」数据，时序如下: 1234T1): 线程 A 更新数据库 (X = 1) T2): 线程 B 更新数据库 (X = 2) T3): 线程 B 更新缓存 (X = 2) T4): 线程 A 更新缓存 (X = 1) 最后结果：缓存中（X=1） 数据库（X=2），从而造成数据不一致。 ② 「先更新数据库，后更新缓存」 同 ① ，这里不在详述。 缓存利用率低 因为该方案是每次数据库发生变更，都会去写缓存，但是缓存中的数据很多都不会被访问到，留在内存中耗费资源。 旁路缓存策略方案 读请求先读缓存，缓存不命中，再读库 写请求做两个动作：写数据库+删除数据缓存 缺点: 异常引发数据不一致问题（这里分两种情况讨论）: 这里的场景和 ii.中的异常场景相同，两步中只要有其中一步发生失败，就会引发数据不一致。 并发引发数据不一致问题: ① 「先删除缓存，后更新数据库」 如果有 2 个线程要并发「读写」 数据，可能会发生以下场景: 1234567891011T1): 线程 A 要更新 X = 2 (原值 X = 1) T2): 线程 A 删除缓存 T3): 线程 B 读缓存，发现不存在，从数据库中读取到旧值（X = 1） T4): 线程 A 将新值写入数据库 (X = 2) T5): 线程 B 将旧值写入缓存 (X = 1) T6): X 的值在缓存中（X = 1），在数据库中 (X = 2), 发生不一致。 可见，先删除缓存，再更新数据库，当发生「读+写」 并发时，存在数据不一致的情况。 ② 「先更新数据库，后删除缓存」 依旧是 2 个线程要并发「读写」 数据。 1234567891011T1): 缓存中 X 不存在（数据库 X = 1）T2): 线程 A 读取数据库，得到旧值 (X = 1)T3): 线程 B 更新数据库（X = 2）T4): 线程 B 删除缓存T5): 线程 A 将旧值写入缓存 (X = 1)T6): X 的值在缓存中（X = 1），在数据库中 (X = 2), 也发生不一致。 其实这个方案就是算是「旁路缓存」策略的实现方案； 仔细思考以下，这种情况理论来说是可能发生的，但实际上发生的概率是「极低」的。 因为它必须满足 3 个条件: 123451-: 缓存刚好失效 2-: 读请求 + 写请求并发 3-: 更新数据库 + 删除缓存的时间(T3+T4) &gt; 读数据库 + 写缓存时间 (T2 + T5) 因为写数据库通常有加锁操作，所以写数据库通常要比读数据库的时间要长，所以，条件3发生的概率极低。 这个策略也是我用在「成长值账户」中的缓存策略； ________________________________________________________________________________________________________________________ 前面说过异常情况，无论是更新缓存还是删除缓存，只要第二步发生失败，就会导致数据库和缓存不一致。 那么这里我们再回过头来讨论下「旁路缓存策略」 - 「先更新数据库，后删除缓存」 策略异常情况下，我们如何保证第二步执行成功？ 重试 12345如果更新数据库成功，删除缓存失败，这里我们就可以无脑的在业务代码中，一直尝试删除缓存；但是这种方案往往存在以下问题：1-: 失败后立即重试，大概率还会「失败」（网络抖动，或者服务异常）;2-: 「重试次数」我们要设置多少才是合理值？3-: 重试会一直「占用」线程资源，无法服务其它请求。 基于以上结论，我们发现这种「同步重试」方式往往不能解决根本问题。 异步重试 1234异步重试步骤：1-: 更新数据库后，发消息到消息队列。2-: 消费者消费队列消息。3-: 删除对应的缓存信息。 这个方案除了需要维护一个重的「消息队列」服务外，看似好像是无懈可击的方案，但是该方案也有一个致命的漏洞，那就是，数据库主从延迟，基于前面我们讨论的并发情况，写数据库往往是操作主库，查库往往是操作从库，所以，会存在，主库处理玩，然后缓存清理后，从库还是旧数据的情况，那么用户从从库中读取旧数据，更新到缓存中时，还是会出现数据不一致的情况。 基于以上总总方案，所以我们引入最终的解决方案: 订阅数据库变更日志，再操作缓存 引入binlog 监控组件 canal 监控binlog变更日志。 优点: 业务只操作数据，无需考虑缓存以及其它相关业务是失败情况，只要写库成功，就会有binlog，余下的工作旧交由下游业务处理，使得业务更加轻量化和简洁化。 canal 不作为master的slave，而是作为一个slave的slave，规避主从延迟造成的数据不一致。 利用binlog 本身的有序性，完全避免并发中的数据不一致问题。 2. 数据变更业务埋点 券变更通知用户业务 传统做法 在每一个涉及券变动的业务中设置业务埋点 动态的更新缓存 缺点: 极大的增加业务代码的复杂度。 极大的增加业务出错概率。 缓存不一致问题。 解决方案: canal + kafka 出错率低 kafka 持久化，失败重试。 和业务主流程解耦。","categories":[{"name":"middleware","slug":"middleware","permalink":"https://gxstax.github.io/categories/middleware/"}],"tags":[{"name":"middleware","slug":"middleware","permalink":"https://gxstax.github.io/tags/middleware/"}]},{"title":"kafka最佳配置实践","slug":"kafka最佳配置实践","date":"2021-12-23T08:01:44.000Z","updated":"2022-02-27T11:30:00.837Z","comments":true,"path":"2021/12/23/kafka最佳配置实践/","link":"","permalink":"https://gxstax.github.io/2021/12/23/kafka%E6%9C%80%E4%BD%B3%E9%85%8D%E7%BD%AE%E5%AE%9E%E8%B7%B5/","excerpt":"","text":"1. broker端 broker集群参数 log.dirs: 这是非常重要的参数，指定了 Broker 需要使用的若干个文件目录路径。要知道这个参数是没有默认值的，这说明什么？这说明它必须由你亲自指定。 log.dir: 注意这是 dir，结尾没有 s，说明它只能表示单个路径，它是补充上一个参数用的。 这两个参数应该怎么设置呢？很简单，你只要设置log.dirs，即第一个参数就好了，不要设置log.dir。 而且更重要的是，在线上生产环境中一定要为log.dirs配置多个路径，具体格式是一个 CSV 格式，也就是用逗号分隔的多个路径， 比如/home/kafka1,/home/kafka2,/home/kafka3这样。如果有条件的话你最好保证这些目录挂载到不同的物理磁盘上。 zookeeper.connect 如果我们是单集群，那么很简单，直接设置zookeeper.connect=zk1:2181,zk2:2181,zk3:2181即可。 这里我们主要考虑多套kafka集群公用一套zookeeper集群, 这时候我们要使用 zookeeper的 chroot，文件挂载方式实现 \\ 如果有两套 Kafka 集群，假设分别叫它们 kafka1 和 kafka2，那么两套集群的zookeeper.connect参数可以这样指定： zk1:2181,zk2:2181,zk3:2181/kafka1和zk1:2181,zk2:2181,zk3:2181/kafka2。 切记 chroot 只需要写一次，而且是加到最后的。\\ zk1:2181/kafka1,zk2:2181/kafka2,zk3:2181/kafka3 这样的格式是不对的。 listeners: PLAINTEXT://host:9092 监听器，其实就是告诉外部连接者要通过什么协议访问指定主机名和端口开放的 Kafka 服务。 从构成上来说，它是若干个逗号分隔的三元组，每个三元组的格式为&lt;协议名称，主机名，端口号&gt;。 这里的协议名称可能是标准的名字，比如 PLAINTEXT 表示明文传输、SSL 表示使用 SSL 或 TLS 加密传输等； 也可能是你自己定义的协议名字，比如CONTROLLER: //localhost:9092。 一旦你自己定义了协议名称，你必须还要指定listener.security.protocol.map参数告诉这个协议底层使用了哪种安全协议， 比如指定listener.security.protocol.map=CONTROLLER:PLAINTEXT表示CONTROLLER这个自定义协议底层使用明文不加密传输数据。 advertised.listeners 和 listeners 相比多了个 advertised。Advertised 的含义表示宣称的、公布的，就是说这组监听器是 Broker 用于对外发布的。 auto.create.topics.enable=false \\ 是否允许自动创建 Topic。 建议最好设置成 false，即不允许自动创建 Topic。 Topic 应该由运维严格把控，决不能允许自行创建任何 Topic unclean.leader.election.enable=false 是否允许 Unclean Leader 选举。 坚决不能让那些落后太多的副本竞选 Leader。 auto.leader.rebalance.enable=false 是否允许定期进行 Leader 选举。 换一次 Leader 代价很高的，原本向 A 发送请求的所有客户端都要切换成向 B 发送请求，而且这种换 Leader 本质上没有任何性能收益。 所以建议你在生产环境中把这个参数设置成 false。 log.retention.{hours|minutes|ms} 控制一条消息数据被保存多长时间。从优先级上来说 ms 设置最高、minutes 次之、hours 最低。 虽然 ms 设置有最高的优先级，但是通常情况下我们还是设置 hours 级别的多一些，比如log.retention.hours=168表示默认保存 7 天的数据，自动删除 7 天前的数据。 如果把 Kafka 当作存储来使用，那么这个值就要相应地调大。 log.retention.bytes 指定 Broker 为消息保存的总磁盘容量大小。 这个值默认是 -1，表明你想在这台 Broker 上保存多少数据都可以，至少在容量方面 Broker 绝对为你开绿灯，不会做任何阻拦。 这个参数真正发挥作用的场景其实是在云上构建多租户的 Kafka 集群：设想你要做一个云上的 Kafka 服务，每个租户只能使用 100GB 的磁盘空间， 为了避免有个“恶意”租户使用过多的磁盘空间，设置这个参数就显得至关重要了。 message.max.bytes 控制 Broker 能够接收的最大消息大小。 默认的 1000012 太少了，还不到 1MB。实际场景中突破 1MB 的消息都是屡见不鲜的， 因此在线上环境中设置一个比较大的值还是比较保险的做法。 毕竟它只是一个标尺而已，仅仅衡量 Broker 能够处理的最大消息大小，即使设置大一点也不会耗费什么磁盘空间的。 防消息丢失 unclean.leader.election.enable = false 它控制的是哪些 Broker 有资格竞选分区的 Leader。 如果一个 Broker 落后原先的 Leader 太多， 那么它一旦成为新的 Leader，必然会造成消息的丢失。故一般都要将该参数设置成 false，即不允许这种情况的发生。 replication.factor &gt;= 3 副本数，最好将消息多保存几份，防止消息丢失的主要机制就是冗余。 min.insync.replicas &gt; 1 该参数控制的是消息至少要被写入到多少个副本才算是“已提交”。设置成大于 1 可以提升消息持久性。 千万不要使用默认值 1。 确保 replication.factor &gt; min.insync.replicas 如果两者相等，那么只要有一个副本挂机，整个分区就无法正常工作了。我们不仅要改善消息的持久性，防止数据丢失，还要在不降低可用性的基础上完成。 推荐设置成 replication.factor = min.insync.replicas + 1。 调优吞吐量 num.replica.fetchers=不要超过cpu核心数 该参数值表示的是 Follower 副本用多少个线程来拉取消息，默认使用 1 个线程。 如果你的 Broker 端 CPU 资源很充足，不妨适当调大该参数值，加快 Follower 副本的同步速度。 因为在实际生产环境中，配置了 acks=all 的 Producer 程序吞吐量被拖累的首要因素，就是副本同步性能。 增加这个值后，你通常可以看到 Producer 端程序的吞吐量增加。\\ 调优JVM参数，避免频繁fullGC 设置堆大小(68GB) 68GB是一个普适的值，可以安心使用，如果想精确调整，建议你可以查看 GC log， 特别是关注 Full GC 之后堆上存活对象的总大小，然后把堆大小设置为该值的 1.5～2 倍。 如果你发现 Full GC 没有被执行过，手动运行 jmap -histo:live &lt; pid &gt; 就能人为触发 Full GC。\\ &nbsp; GC收集器选择(G1) 竭力避免 Full GC : 如果你的 Kafka 环境中经常出现 Full GC，你可以配置 JVM 参数 -XX:+PrintAdaptiveSizePolicy，来探查一下到底是谁导致的 Full GC。 大对象 : 所谓的大对象，一般是指至少占用半个区域（Region）大小的对象。举个例子，如果你的区域尺寸是 2MB，那么超过 1MB 大小的对象就被视为是大对象。要解决这个问题，除了增加堆大小之外，你还可以适当地增加区域大小，设置方法是增加 JVM 启动参数 -XX:+G1HeapRegionSize=N。默认情况下，如果一个对象超过了 N/2，就会被视为大对象，从而直接被分配在大对象区。如果你的 Kafka 环境中的消息体都特别大，就很容易出现这种大对象分配的问题。 调优延时 num.replica.fetchers 增加 num.replica.fetchers 值以加快 Follower 副本的拉取速度，减少整个消息处理的延时。 2. producer 端 防消息丢失 不要使用 producer.send(msg)，而要使用 producer.send(msg, callback)。记住，一定要使用带有回调通知的 send 方法。 acks = all acks 是 Producer 的一个参数，代表了你对“已提交”消息的定义。 如果设置成 all，则表明所有副本 Broker 都要接收到消息，该消息才算是“已提交”。这是最高等级的“已提交”定义。 retries &gt; 0 设置 retries 为一个较大的值。这里的 retries 为自动重试次数。、 当出现网络的瞬时抖动时，消息发送可能会失败，此时配置了 retries &gt; 0 的 Producer 能够自动重试消息发送，避免消息丢失。 调优吞吐量 batch.size=1048576 该参数值代表生产者一批次发送多少字节大小的数据； 如果你想要增加吞吐量，那么尽量调大该参数值，该值默认16KB， 假设你的消息体大小是 1KB，默认一个消息批次也就大约 16 条消息，显然太小了。 我们还是希望 Producer 能一次性发送更多的消息。 linger.ms 该值是和batch.size配对使用的参数，表示每批次缓存时间； 也就是说，如果你设置batch.size=5000， 如果从上一发送批次发送到现在时间，超过了linger.ms设置的时间，那么即使未达到batch.size设置的5000，这时候也会发送。 compression.type=lz4/zstd 配置压缩算法，减少I/O传输量，从而提升吞吐量。 当前，和 Kafka 适配最好的两个压缩算法是 LZ4 和 zstd，不妨一试。 acks=0/1 该参数设置是和防消息丢失配置想违背，如果你追求高吞吐量，那么就要承担消息丢失的风险。 设置为 0, 可以不必等待副本确认就可以直接返回处理下一批数据； 设置为 1, 也只需等待一个broker副本确认提交成功，就进行下一批数据处理。 retries=0 这个参数也和防消息丢失的配置相违背，同样的追求高吞吐量，就必须承担消息丢失风险。 禁用重试当然会提高吞吐量，但是消息发送正确性就得不到保障，这里还是要根据自己的业务做合适的参数调整。 buffer.memory 如果你在多个线程中共享一个 Producer 实例，就可能会碰到缓冲区不够用的情形。 倘若频繁地遭遇 TimeoutException：Failed to allocate memory within the configured max blocking time 这样的异常， 那么你就必须显式地增加 buffer.memory 参数值，确保缓冲区总是有空间可以申请的。 调优延时 linger.ms=0 低延时，就是我们希望要把消息尽快的送出去，所以，设置这个参数为 0，意味着只要有消息就发送，不用等待。 compression.type=none 不要设置压缩算法。 毕竟压缩也是要耗费一定的时间的。 acks=1 该值参数尽量设置的小一点。 Follower 副本同步往往是降低 Producer 端吞吐量和增加延时的首要原因。 3. consumer 端 防消息丢失 enable.auto.commit=false 确保消息消费完成再提交。并采用手动提交位移的方式。 这对于单 Consumer 多线程处理的场景而言是至关重要的。 调优吞吐量 采用多 Consumer 进程或线程同时消费数据。 适当采用多线程方案增加吞吐量。 不过该方案在实施起来是有一定的复杂度的，操作不当还会造成数据丢失， 我在项目中也写了一个多线程消费者的案例，欢迎大家来讨论。 fetch.min.bytes 该参数表示 Kafka Broker 端积攒多少字节，就可以返回给 Consumer端。 默认是 1 字节，表示只要 Kafka Broker 端积攒了 1 字节的数据，就可以返回给 Consumer 端， 这实在是太小了。我们还是让 Broker 端一次性多返回点数据吧。 调优延时 fetch.min.bytes=1 在 Consumer 端，我们保持 fetch.min.bytes=1 即可，也就是说， 只要 Broker 端有能返回的数据，立即令其返回给 Consumer，缩短 Consumer 消费延时。","categories":[{"name":"middleware","slug":"middleware","permalink":"https://gxstax.github.io/categories/middleware/"}],"tags":[{"name":"middleware","slug":"middleware","permalink":"https://gxstax.github.io/tags/middleware/"}]},{"title":"mysql命令","slug":"mysql命令","date":"2020-02-23T08:01:44.000Z","updated":"2022-02-27T11:30:00.838Z","comments":true,"path":"2020/02/23/mysql命令/","link":"","permalink":"https://gxstax.github.io/2020/02/23/mysql%E5%91%BD%E4%BB%A4/","excerpt":"","text":"","categories":[{"name":"db","slug":"db","permalink":"https://gxstax.github.io/categories/db/"}],"tags":[{"name":"db","slug":"db","permalink":"https://gxstax.github.io/tags/db/"}]},{"title":"网络设备状态标识","slug":"网络设备状态标识","date":"2019-09-17T06:46:39.000Z","updated":"2022-02-27T11:30:00.838Z","comments":true,"path":"2019/09/17/网络设备状态标识/","link":"","permalink":"https://gxstax.github.io/2019/09/17/%E7%BD%91%E7%BB%9C%E8%AE%BE%E5%A4%87%E7%8A%B6%E6%80%81%E6%A0%87%E8%AF%86/","excerpt":"","text":"记录一下网络设备的各个标志都是什么意思；我这里以我的一台虚拟机机为例（虚拟软件：virtualbox，系统：centos7）首先我们运行命令：ip addr 查看网络设备信息： ![image-20220223150205002](/Users/mayi/Library/Application Support/typora-user-images/image-20220223150205002.png) &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; :net_device flags，网络设备的状态标识 1234BROADCAST：表示这个网卡有广播地址，可以发送广播包；MULTICAST：表示这个网卡可以发送多播包；UP：表示网卡处于启动状态；LOWER_UP：表示L1是启动的，也就是插着网线； mtu 1500 12MTU: 是二层 MAC 层的概念。 MAC 层有 MAC 的头，mtu 1500就表示-以太网规定MAC和正文加起来不能超过1500字节。 qdisc pfifo_fast： 1qdisc: 是queueing discipline （排队规则），内核如果需要通过某个网络接口发送数据包，他们都需要按这个接口配置的 qdisc 把数据包加入队列； scope global : 1在ip地址后面有一个scope global，global说明这张网卡是可以对外的，可以接受来自任何地方的包。 scope host : 12像lo这里是个scope host，说明这张网卡仅可以提供本机相互通信。lo 全称是loopback，又称环回接口，往往会被分配到127.0.0.1 这个地址。这个地址用于本机通信，经过内核处理后直接返回，不会在任何网络中出现。","categories":[{"name":"network","slug":"network","permalink":"https://gxstax.github.io/categories/network/"}],"tags":[{"name":"network","slug":"network","permalink":"https://gxstax.github.io/tags/network/"}]},{"title":"linux编程-文件读取操作","slug":"linux编程-文件读取操作","date":"2019-05-28T02:21:56.000Z","updated":"2022-02-27T11:30:00.838Z","comments":true,"path":"2019/05/28/linux编程-文件读取操作/","link":"","permalink":"https://gxstax.github.io/2019/05/28/linux%E7%BC%96%E7%A8%8B-%E6%96%87%E4%BB%B6%E8%AF%BB%E5%8F%96%E6%93%8D%E4%BD%9C/","excerpt":"","text":"这里写一个最简单的文件读取的操作流程： 安装环境 我的系统是centos7，默认是不带有linux函数系统手册的，所以有需要的要先安装一下。具体的命令如下： 1$ yum -y install man-pages 出现如下提示，说明安装成功； 1234$ Running transaction 正在安装 : man-pages-3.53-5.el7.noarch$ 1/1 验证中 : man-pages-3.53-5.el7.noarch$ 1/1 已安装: man-pages.noarch 0:3.53-5.el7$ 完毕！ 开始着手写我们的程序 文件读取操作 我们这里随便建一个c程序，就叫open_test1.c,首先写一个main函数 1234int main(void)&#123; return 0;&#125; 下面我们需要查询手册，来看linux系统是怎么打开一个文件的；这里我们要使用man 2 open 命令查看： 1$ man 2 open OPEN(2) BSD System Calls Manual OPEN(2) NAME open, openat -- open or create a file for reading or writing SYNOPSIS #include &lt;fcntl.h&gt; int open(const char *path, int oflag, ...); int openat(int fd, const char *path, int oflag, ...); DESCRIPTION The file name specified by path is opened for reading and/or writing, as specified by the argument oflag; the file descriptor is returned to the calling process. 12345The oflag argument may indicate that the file is to be created if it does not exist (by speci-fying the O_CREAT flag). In this case, open() and openat() require an additional argumentmode_t mode; the file is created with mode mode as described in chmod(2) and modified by theprocess&#x27; umask value (see umask(2)).省略部分内容.......... 具体的描述如如上面所示，所以我们根据他给我们的提示，写一个打开文件的操作，我们的程序中增加如下代码： 12345678910111213141516171819202122#include &lt;stdio.h&gt;#include &lt;sys/types.h&gt;#include &lt;sys/stat.h&gt;#include &lt;fcntl.h&gt;int main(void)&#123; int fd = 0; fd = open(&quot;./file.txt&quot;,O_RDWR); if(-1 == fd) &#123; printf(&quot;open fail\\n&quot;); return 0; &#125; else &#123; printf(&quot;open ok\\n&quot;); &#125; // 关闭文件 close(fd);&#125; 如果文件打开正常，会打印出，open ok； 写文件操作 同样的我们去查写操作手册，命令为： 1$ man 2 write WRITE(2) BSD System Calls Manual WRITE(2) NAME pwrite, write, writev -- write output LIBRARY Standard C Library (libc, -lc) SYNOPSIS #include &lt;unistd.h&gt; ssize_t pwrite(int fildes, const void *buf, size_t nbyte, off_t offset); ssize_t write(int fildes, const void *buf, size_t nbyte); #include &lt;sys/uio.h&gt; ssize_t writev(int fildes, const struct iovec *iov, int iovcnt); DESCRIPTION 省略部分内容………………… 所以我们的程序中增加代码如下： 123456789101112131415161718192021222324252627282930313233#include &lt;stdio.h&gt;#include &lt;sys/types.h&gt;#include &lt;sys/stat.h&gt;#include &lt;fcntl.h&gt;#include &lt;unistd.h&gt; int main(void)&#123; int fd = 0; // 打开file.txt文件 fd = open(&quot;./file.txt&quot;,O_RDWR); if(-1 == fd) &#123; printf(&quot;open fail\\n&quot;); return 0; &#125; else &#123; printf(&quot;open ok\\n&quot;); &#125; // 往file.txt文件里面写入hello world char buf[] = &quot;hello world&quot;; write(fd,(void *)buf,11); //ssize_t write(int fd, const void *buf, size_t count); // 关闭文件 close(fd);&#125; 读取写入文件的到缓冲区，然后输出 读取file.txt文件里的内容到buf2中，然后输出，同样我们查看读文件的函数命令: 1$ man 2 read READ(2) BSD System Calls Manual READ(2) NAME pread, read, readv -- read input LIBRARY Standard C Library (libc, -lc) SYNOPSIS #include &lt;sys/types.h&gt; #include &lt;sys/uio.h&gt; #include &lt;unistd.h&gt; 123456789ssize_tpread(int d, void *buf, size_t nbyte, off_t offset);ssize_tread(int fildes, void *buf, size_t nbyte);ssize_treadv(int d, const struct iovec *iov, int iovcnt);省略剩余内容..................... 然后我们的程序增加如下： 12345678910111213141516171819202122232425262728293031323334353637383940414243#include &lt;sys/types.h&gt;#include &lt;sys/stat.h&gt;#include &lt;fcntl.h&gt;#include &lt;unistd.h&gt;#include &lt;stdio.h&gt;int main(void)&#123; int fd = 0; // 打开file.txt文件 fd = open(&quot;./file.txt&quot;,O_RDWR); if(-1 == fd) &#123; printf(&quot;open fail\\n&quot;); return 0; &#125; else &#123; printf(&quot;open ok\\n&quot;); &#125; // 往file.txt文件里面写入hello world char buf[] = &quot;hello world&quot;; write(fd,(void *)buf,11); //ssize_t write(int fd, const void *buf, size_t count); // 把文件指向调到文件头部位置 lseek(fd, SEEK_SET, 0); //off_t lseek(int fd, off_t offset, int whence); // 读取file.txt的内容到buf2中，然后输出 char buf2[30] = &#123;0&#125;; read(fd, buf2, sizeof(buf2)); printf(&quot;buf2 = %s\\n&quot;, buf2); // 关闭文件 close(fd); return 0;&#125; 到此为止，我们的程序基本就算是写完了！ 运行 那么让我们编译运行一下： 1$ gcc open_test1.c 如果没有报错，则说明我们的程序没有问题：编译后会出现一个a.out文件如下： 12345$ ll总用量 20-rwxr-xr-x. 1 root root 8704 5月 28 10:19 a.out-rw-r–r--. 1 root root 11 5月 28 09:52 file.txt-rw-r–r--. 1 root root 757 5月 28 10:12 open_test1.c 然后让我们运行一下看一下结果： 123$ ./a.outopen okbuf2 = hello world 成功输出！！！ 到这里一个简单的文件打开-&gt;写入-&gt;输出的简单操作就完成了。","categories":[{"name":"linuxProgram","slug":"linuxProgram","permalink":"https://gxstax.github.io/categories/linuxProgram/"}],"tags":[{"name":"linuxProgram","slug":"linuxProgram","permalink":"https://gxstax.github.io/tags/linuxProgram/"}]},{"title":"linux命令","slug":"linux命令","date":"2019-04-13T09:07:28.000Z","updated":"2022-02-27T11:30:00.837Z","comments":true,"path":"2019/04/13/linux命令/","link":"","permalink":"https://gxstax.github.io/2019/04/13/linux%E5%91%BD%E4%BB%A4/","excerpt":"","text":"Linux基本命令 目录示意 /:根目录整个文件系统，有一个顶层目录，称为根。 bin:存放一些可执行的程序、命令。 boot: 系统启动所需的一些文件。 dev:系统中的设备(硬件在linux中通过“文件”来标识) etc:存放系统、软件的配置文件 home:普通用户目录的主目录，以用户名命名。 home/fred lib:系统库目录(32位) lib64: 系统库目录(64位) media:媒体 mnt:挂载外部存储设备的文件目录 opt proc root:root用户的主目录 run sbin:系统的可执行命令 srv sys test tmp:系统临时目录 usr:共享资源目录(多个用户可以共享该目录中的程序) var 命令 ls命令 1234ls /: 查看根目录ls -l: 显示详细信息ls -lh: 显示跟符合人类查看方式 ls -a: 显示隐藏文件 目录切换 123pwd: 查看当前所在目录cd: 切换目录cd ...: 退回到上一级目录cat 创建文件夹 123mkdir aaa: 相对路径写法mkdir /bbb: 绝对路径写法mkdir -p aaa/bbb/ccc: 级联创建目录 删除目录/文件 123rm: 删除目录rm -r: 递归删除rm -rf: 递归删除，不提示 查看信息 12touch: 创建空文件cat: 查看文件内容 编辑 123456vi : 编辑文件-i: 编辑模式 -o: 编辑模式(直接到下一行)-w: 保存-q: 退出esc: 退出编辑 Vim快捷键 (非编辑模式下) 12345678910111213141516a: 在光标后一位开始插入A: 在该行的最后插入I: 在该行的最前插入yy: 复制整行 3yy: 复制三行p: 粘贴gg: 直接跳到文件首行G: 直接跳到文件的末行dd: 删除一行3dd: 删除三行/: 搜索内容,n匹配下一个 u:undo(撤销) ctrl+r:redo(执行之前撤销的) :set nu: 设置行号:set nonu: 设置不显示行号:q!: 强制不保存退出fg 程序编号: 切换后台挂起程序jobs: 查看后台挂起的程序ctrl+z: 将程序挂起 拷贝 1cp a.txt b.txt: 将a.txt 拷贝为b.txt 移动/改名 12mv a.txt aa.txt: 将a.txt 改为 aa.txtmv a.txt aa/aa.txt: 将a.txt 移动到 aa/aa.txt 权限 添加用户 1useradd fred passwd 1234: 添加 fred 用户并设置密码为 1234 linux文件权限的描述格式 1234567891011121314d rwx rwx rwxd: 标识节点类型(d:文件夹 -:文件 |:链接)r: 可读w: 可写x: 可执行第一组rwx: 表示这个文件的拥有者对它的权限第二组rwx: 表示这个文件的所属组用户对它的权限第三组rwx: 表示这个文件的其他用户(除以上两种)对它的权限使用二进制表示权限:例如-rw-rw-r–二进制表示为110,110,100，十进制表示为664补充:r: 对文件来说，是可读取内容;对文件夹来说，是可以lsw: 对文件来说，是可修改文件的内容;对文件夹来说，是可以在其中创建或者删除子节点x: 对文件来说，是能否运行这个文件;对文件夹来说，是能否cd进入这个目录 用户管理 增加用户 1234useradd ant: 增加 ant 用户passwd ant: 给用户ant设置密码userdel -r 用户名: 删除用户(加一个-r表示把用户及用户的主目录都删除)exit: 退出会话 增加用户组 12345groupadd 组名: 增加组usermod -g 组名 用户名: 将用户添加到组中usermod -G 组名1,组名2 用户名: 将用户添加到多个组中gpasswd -d 用户名 组名: 将用户从组中删除 —例如:gpasswd -d jack root | gpasswd -d jack sys 查看所属组 12groups: 查看当前用户所属组 groups jack: 查看指定用户所属组 su 和 sudo 1234su: 身份切换su username 输入密码(root切换不需要输入密码)sudo: 让普通用户具备root的权限(需要配置 /etc/sudoers) 了解完su和sudo，是不是发现sudo有太多的优点了。 su方式切换是须要输入目标用户的password。而sudo仅仅须要 输入自己的password，所以sudo能够保护目标用户的password不外流的。 当帮root管理系统的时候，su是直接将 root全部权利交给用户。而sudo能够更好分工，仅仅要配置好/etc/sudoers，这样sudo能够保护系统更安全，并且分 工明白，有条不紊。","categories":[{"name":"linux","slug":"linux","permalink":"https://gxstax.github.io/categories/linux/"}],"tags":[{"name":"linux","slug":"linux","permalink":"https://gxstax.github.io/tags/linux/"}]},{"title":"java指令码 字节码 对别","slug":"java指令码-字节码-对别","date":"2019-04-03T03:45:52.000Z","updated":"2022-02-27T11:30:00.837Z","comments":true,"path":"2019/04/03/java指令码-字节码-对别/","link":"","permalink":"https://gxstax.github.io/2019/04/03/java%E6%8C%87%E4%BB%A4%E7%A0%81-%E5%AD%97%E8%8A%82%E7%A0%81-%E5%AF%B9%E5%88%AB/","excerpt":"","text":"java 【指令码】【子节码】 对比 指令从0x00-0xc9 没有0xba 常量入栈指令 指令码 操作码（助记符） 操作数 描述（栈指操作数栈） 0x01 aconst_null null值入栈。 0x02 iconst_m1 -1(int)值入栈。 0x03 iconst_0 0(int)值入栈。 0x04 iconst_1 1(int)值入栈。 0x05 iconst_2 2(int)值入栈。 0x06 iconst_3 3(int)值入栈。 0x07 iconst_4 4(int)值入栈。 0x08 iconst_5 5(int)值入栈。 0x09 lconst_0 0(long)值入栈。 0x0a lconst_1 1(long)值入栈。 0x0b fconst_0 0(float)值入栈。 0x0c fconst_1 1(float)值入栈。 0x0d fconst_2 2(float)值入栈。 0x0e dconst_0 0(double)值入栈。 0x0f dconst_1 1(double)值入栈。 0x10 bipush valuebyte valuebyte值带符号扩展成int值入栈。 0x11 sipush valuebyte1 valuebyte2 (valuebyte1 &lt;&lt; 8) | valuebyte2 值带符号扩展成int值入栈。 0x12 ldc indexbyte1 常量池中的常量值（int, float, string reference, object reference）入栈。 0x13 ldc_w indexbyte1 indexbyte2 常量池中常量（int, float, string reference, object reference）入栈。 0x14 ldc2_w indexbyte1 indexbyte2 常量池中常量（long, double）入栈。 局部变量值转载到栈中指令 指令码 操作码（助记符） 操作数 描述（栈指操作数栈） 0x19 (wide)aload indexbyte 从局部变量indexbyte中装载引用类型值入栈。 0x2a aload_0 从局部变量0中装载引用类型值入栈。 0x2b aload_1 从局部变量1中装载引用类型值入栈。 0x2c aload_2 从局部变量2中装载引用类型值入栈。 0x2d aload_3 从局部变量3中装载引用类型值入栈。 0x15 (wide)iload indexbyte 从局部变量indexbyte中装载int类型值入栈。 0x1a iload_0 从局部变量0中装载int类型值入栈。 0x1b iload_1 从局部变量1中装载int类型值入栈。 0x1c iload_2 从局部变量2中装载int类型值入栈。 0x1d iload_3 从局部变量3中装载int类型值入栈。 0x16 (wide)lload indexbyte 从局部变量indexbyte中装载long类型值入栈。 0x1e lload_0 从局部变量0中装载int类型值入栈。 0x1f lload_1 从局部变量1中装载int类型值入栈。 0x20 lload_2 从局部变量2中装载int类型值入栈。 0x21 lload_3 从局部变量3中装载int类型值入栈。 0x17 (wide)fload indexbyte 从局部变量indexbyte中装载float类型值入栈。 0x22 fload_0 从局部变量0中装载float类型值入栈。 0x23 fload_1 从局部变量1中装载float类型值入栈。 0x24 fload_2 从局部变量2中装载float类型值入栈。 0x25 fload_3 从局部变量3中装载float类型值入栈。 0x18 (wide)dload indexbyte 从局部变量indexbyte中装载double类型值入栈。 0x26 dload_0 从局部变量0中装载double类型值入栈。 0x27 dload_1 从局部变量1中装载double类型值入栈。 0x28 dload_2 从局部变量2中装载double类型值入栈。 0x29 dload_3 从局部变量3中装载double类型值入栈。 0x32 aaload 从引用类型数组中装载指定项的值。 0x2e iaload 从int类型数组中装载指定项的值。 0x2f laload 从long类型数组中装载指定项的值。 0x30 faload 从float类型数组中装载指定项的值。 0x31 daload 从double类型数组中装载指定项的值。 0x33 baload 从boolean类型数组或byte类型数组中装载指定项的值（先转换为int类型值，后压栈）。 0x34 caload 从char类型数组中装载指定项的值（先转换为int类型值，后压栈）。 0x35 saload 从short类型数组中装载指定项的值（先转换为int类型值，后压栈）。 将栈顶值保存到局部变量中指令 指令码 操作码（助记符） 操作数 描述（栈指操作数栈） 0x3a (wide)astore indexbyte 将栈顶引用类型值保存到局部变量indexbyte中。 0x4b astroe_0 将栈顶引用类型值保存到局部变量0中。 0x4c astore_1 将栈顶引用类型值保存到局部变量1中。 0x4d astore_2 将栈顶引用类型值保存到局部变量2中。 0x4e astore_3 将栈顶引用类型值保存到局部变量3中。 0x36 (wide)istore indexbyte 将栈顶int类型值保存到局部变量indexbyte中。 0x3b istore_0 将栈顶int类型值保存到局部变量0中。 0x3c istore_1 将栈顶int类型值保存到局部变量1中。 0x3d istore_2 将栈顶int类型值保存到局部变量2中。 0x3e istore_3 将栈顶int类型值保存到局部变量3中。 0x37 (wide)lstore indexbyte 将栈顶long类型值保存到局部变量indexbyte中。 0x3f lstore_0 将栈顶long类型值保存到局部变量0中。 0x40 lstore_1 将栈顶long类型值保存到局部变量1中。 0x41 lstore_2 将栈顶long类型值保存到局部变量2中。 0x42 lstroe_3 将栈顶long类型值保存到局部变量3中。 0x38 (wide)fstore indexbyte 将栈顶float类型值保存到局部变量indexbyte中。 0x43 fstore_0 将栈顶float类型值保存到局部变量0中。 0x44 fstore_1 将栈顶float类型值保存到局部变量1中。 0x45 fstore_2 将栈顶float类型值保存到局部变量2中。 0x46 fstore_3 将栈顶float类型值保存到局部变量3中。 0x39 (wide)dstore indexbyte 将栈顶double类型值保存到局部变量indexbyte中。 0x47 dstore_0 将栈顶double类型值保存到局部变量0中。 0x48 dstore_1 将栈顶double类型值保存到局部变量1中。 0x49 dstore_2 将栈顶double类型值保存到局部变量2中。 0x4a dstore_3 将栈顶double类型值保存到局部变量3中。 0x53 aastore 将栈顶引用类型值保存到指定引用类型数组的指定项。 0x4f iastore 将栈顶int类型值保存到指定int类型数组的指定项。 0x50 lastore 将栈顶long类型值保存到指定long类型数组的指定项。 0x51 fastore 将栈顶float类型值保存到指定float类型数组的指定项。 0x52 dastore 将栈顶double类型值保存到指定double类型数组的指定项。 0x54 bastroe 将栈顶boolean类型值或byte类型值保存到指定boolean类型数组或byte类型数组的指定项。 0x55 castore 将栈顶char类型值保存到指定char类型数组的指定项。 0x56 sastore 将栈顶short类型值保存到指定short类型数组的指定项。 wide指令 指令码 操作码（助记符） 操作数 描述（栈指操作数栈） 0xc4 wide 使用附加字节扩展局部变量索引（iinc指令特殊）。 通用（无类型）栈操作指令 指令码 操作码（助记符） 操作数 描述（栈指操作数栈） 0x00 nop 空操作。 0x57 pop 从栈顶弹出一个字长的数据。 0x58 pop2 从栈顶弹出两个字长的数据。 0x59 dup 复制栈顶一个字长的数据，将复制后的数据压栈。 0x5a dup_x1 复制栈顶一个字长的数据，弹出栈顶两个字长数据，先将复制后的数据压栈，再将弹出的两个字长数据压栈。 0x5b dup_x2 复制栈顶一个字长的数据，弹出栈顶三个字长的数据，将复制后的数据压栈，再将弹出的三个字长的数据压栈。 0x5c dup2 复制栈顶两个字长的数据，将复制后的两个字长的数据压栈。 0x5d dup2_x1 复制栈顶两个字长的数据，弹出栈顶三个字长的数据，将复制后的两个字长的数据压栈，再将弹出的三个字长的数据压栈。 0x5e dup2_x2 复制栈顶两个字长的数据，弹出栈顶四个字长的数据，将复制后的两个字长的数据压栈，再将弹出的四个字长的数据压栈。 0x5f swap 交换栈顶两个字长的数据的位置。Java指令中没有提供以两个字长为单位的交换指令。 类型转换指令 指令码 操作码（助记符） 操作数 描述（栈指操作数栈） 0x86 i2f 将栈顶int类型值转换为float类型值。 0x85 i2l 将栈顶int类型值转换为long类型值。 0x87 i2d 将栈顶int类型值转换为double类型值。 0x8b f2i 将栈顶float类型值转换为int类型值。 0x8c f2l 将栈顶float类型值转换为long类型值。 0x8d f2d 将栈顶float类型值转换为double类型值。 0x88 l2i 将栈顶long类型值转换为int类型值。 0x89 l2f 将栈顶long类型值转换为float类型值。 0x8a l2d 将栈顶long类型值转换double类型值。 0x8e d2i 将栈顶double类型值转换为int类型值。 0x90 d2f 将栈顶double类型值转换为float类型值。 0x8f d2l 将栈顶double类型值转换为long类型值。 0x91 i2b 将栈顶int类型值截断成byte类型，后带符号扩展成int类型值入栈。 0x92 i2c 将栈顶int类型值截断成char类型值，后带符号扩展成int类型值入栈。 0x93 i2s 将栈顶int类型值截断成short类型值，后带符号扩展成int类型值入栈。 整数运算 指令码 操作码（助记符） 操作数 描述（栈指操作数栈） 0x60 iadd 将栈顶两int类型数相加，结果入栈。 0x64 isub 将栈顶两int类型数相减，结果入栈。 0x68 imul 将栈顶两int类型数相乘，结果入栈。 0x6c idiv 将栈顶两int类型数相除，结果入栈。 0x70 irem 将栈顶两int类型数取模，结果入栈。 0x74 ineg 将栈顶int类型值取负，结果入栈。 0x61 ladd 将栈顶两long类型数相加，结果入栈。 0x65 lsub 将栈顶两long类型数相减，结果入栈。 0x69 lmul 将栈顶两long类型数相乘，结果入栈。 0x6d ldiv 将栈顶两long类型数相除，结果入栈。 0x71 lrem 将栈顶两long类型数取模，结果入栈。 0x75 lneg 将栈顶long类型值取负，结果入栈。 0x84 (wide)iinc indexbyte constbyte 将整数值constbyte加到indexbyte指定的int类型的局部变量中。 浮点运算 指令码 操作码（助记符） 操作数 描述（栈指操作数栈） 0x62 fadd 将栈顶两float类型数相加，结果入栈。 0x66 fsub 将栈顶两float类型数相减，结果入栈。 0x6a fmul 将栈顶两float类型数相乘，结果入栈。 0x6e fdiv 将栈顶两float类型数相除，结果入栈。 0x72 frem 将栈顶两float类型数取模，结果入栈。 0x76 fneg 将栈顶float类型值取反，结果入栈。 0x63 dadd 将栈顶两double类型数相加，结果入栈。 0x67 dsub 将栈顶两double类型数相减，结果入栈。 0x6b dmul 将栈顶两double类型数相乘，结果入栈。 0x6f ddiv 将栈顶两double类型数相除，结果入栈。 0x73 drem 将栈顶两double类型数取模，结果入栈。 0x77 dneg 将栈顶double类型值取负，结果入栈。 逻辑运算——移位运算 指令码 操作码（助记符） 操作数 描述（栈指操作数栈） 0x78 ishl 左移int类型值。 0x79 lshl 左移long类型值。 0x7a ishr 算术右移int类型值。 0x7b lshr 算术右移long类型值。 0x7c iushr 逻辑右移int类型值。 0x7d lushr 逻辑右移long类型值。 逻辑运算——按位布尔运算 指令码 操作码（助记符） 操作数 描述（栈指操作数栈） 0x73 iand 对int类型按位与运算。 0x7f land 对long类型的按位与运算。 0x80 ior 对int类型的按位或运算。 0x81 lor 对long类型的按位或运算。 0x82 ixor 对int类型的按位异或运算。 0x83 lxor 对long类型的按位异或运算。 控制流指令——条件跳转指令 指令码 操作码（助记符） 操作数 描述（栈指操作数栈） 0x99 ifeq branchbyte1 branchbyte2 若栈顶int类型值为0则跳转。 0x9a ifne branchbyte1 branchbyte2 若栈顶int类型值不为0则跳转。 0x9b iflt branchbyte1 branchbyte2 若栈顶int类型值小于0则跳转。 0x9e ifle branchbyte1 branchbyte2 若栈顶int类型值小于等于0则跳转。 0x9d ifgt branchbyte1 branchbyte2 若栈顶int类型值大于0则跳转。 0x9c ifge branchbyte1 branchbyte2 若栈顶int类型值大于等于0则跳转。 0x9f if_icmpeq branchbyte1 branchbyte2 若栈顶两int类型值相等则跳转。 0xa0 if_icmpne branchbyte1 branchbyte2 若栈顶两int类型值不相等则跳转。 0xa1 if_icmplt branchbyte1 branchbyte2 若栈顶两int类型值前小于后则跳转。 0xa4 if_icmple branchbyte1 branchbyte2 若栈顶两int类型值前小于等于后则跳转。 0xa3 if_icmpgt branchbyte1 branchbyte2 若栈顶两int类型值前大于后则跳转。 0xa2 if_icmpge branchbyte1 branchbyte2 若栈顶两int类型值前大于等于后则跳转。 0xc6 ifnull branchbyte1 branchbyte2 若栈顶引用值为null则跳转。 0xc7 ifnonnull branchbyte1 branchbyte2 若栈顶引用值不为null则跳转。 0xa5 if_acmpeq branchbyte1 branchbyte2 若栈顶两引用类型值相等则跳转。 0xa6 if_acmpne branchbyte1 branchbyte2 若栈顶两引用类型值不相等则跳转。 控制流指令——比较指令 指令码 操作码（助记符） 操作数 描述（栈指操作数栈） 0x94 lcmp 比较栈顶两long类型值，前者大，1入栈；相等，0入栈；后者大，-1入栈。 0x95 fcmpl 比较栈顶两float类型值，前者大，1入栈；相等，0入栈；后者大，-1入栈；有NaN存在，-1入栈。 0x96 fcmpg 比较栈顶两float类型值，前者大，1入栈；相等，0入栈；后者大，-1入栈；有NaN存在，-1入栈。 0x97 dcmpl 比较栈顶两double类型值，前者大，1入栈；相等，0入栈；后者大，-1入栈；有NaN存在，-1入栈。 0x98 dcmpg 比较栈顶两double类型值，前者大，1入栈；相等，0入栈；后者大，-1入栈；有NaN存在，-1入栈。 控制流指令——无条件跳转指令 指令码 操作码（助记符） 操作数 描述（栈指操作数栈） 0xa7 goto branchbyte1 branchbyte2 无条件跳转到指定位置。 0xc8 goto_w branchbyte1 branchbyte2 branchbyte3 branchbyte4 无条件跳转到指定位置（宽索引）。 控制流指令——表跳转指令 指令码 操作码（助记符） 操作数 描述（栈指操作数栈） 0xaa tableswitch &lt;0-3bytepad&gt; defaultbyte1 defaultbyte2 defaultbyte3 defaultbyte4 lowbyte1 lowbyte2 lowbyte3 lowbyte4 highbyte1 highbyte2 highbyte3 highbyte4 jump offsets… 通过索引访问跳转表，并跳转。 0xab lookupswitch &lt;0-3bytepad&gt; defaultbyte1 defaultbyte2 defaultbyte3 defaultbyte4 npairs1 npairs2 npairs3 npairs4 match offsets 通过键值访问跳转表，并跳转。 控制流指令——异常和finally 指令码 操作码（助记符） 操作数 描述（栈指操作数栈） 0xbf athrow 抛出异常。 0xa8 jsr branchbyte1 branchbyte2 跳转到子例程序。 0xc9 jsr_w branchbyte1 branchbyte2 branchbyte3 branchbyte4 跳转到子例程序（宽索引）。 0xa9 (wide)ret indexbyte 返回子例程序。 对象操作指令 指令码 操作码（助记符） 操作数 描述（栈指操作数栈） 0xbb new indexbyte1 indexbyte2 创建新的对象实例。 0xc0 checkcast indexbyte1 indexbyte 类型强转。 0xc1 instanceof indexbyte1 indexbyte2 判断类型。 0xb4 getfield indexbyte1 indexbyte2 获取对象字段的值。 0xb5 putfield indexbyte1 indexbyte2 给对象字段赋值。 0xb2 getstatic indexbyte1 indexbyte2 获取静态字段的值。 0xb3 putstatic indexbyte1 indexbyte2 给静态字段赋值。 数组操作指令 指令码 操作码（助记符） 操作数 描述（栈指操作数栈） 0xbc newarray atype 创建type类型的数组。 0xbd anewarray indexbyte1 indexbyte2 创建引用类型的数组。 0xbe arraylength 获取一维数组的长度。 0xc5 multianewarray indexbyte1 indexbyte2 dimension 创建dimension维度的数组。 方法调用指令 指令码 操作码（助记符） 操作数 描述（栈指操作数栈） 0xb7 invokespecial indexbyte1 indexbyte2 编译时方法绑定调用方法。 0xb6 invokevirtual indexbyte1 indexbyte2 运行时方法绑定调用方法。 0xb8 invokestatic indexbyte1 indexbyte2 调用静态方法。 0xb9 invokeinterface indexbyte1 indexbyte2 count 0 调用接口方法。 方法返回指令 指令码 操作码（助记符） 操作数 描述（栈指操作数栈） 0xac ireturn 返回int类型值。 0xad lreturn 返回long类型值。 0xae freturn 返回float类型值。 0xaf dreturn 返回double类型值。 0xb0 areturn 返回引用类型值。 0xb1 return void函数返回。 线程同步指令 指令码 操作码（助记符） 操作数 描述（栈指操作数栈） 0xc2 monitorenter 进入并获得对象监视器。 0xc3 monitorexit 释放并退出对象监视器。","categories":[{"name":"jvm","slug":"jvm","permalink":"https://gxstax.github.io/categories/jvm/"}],"tags":[{"name":"jvm","slug":"jvm","permalink":"https://gxstax.github.io/tags/jvm/"}]},{"title":"使用静态内部类实现单例","slug":"使用静态内部类实现单例","date":"2018-11-23T03:08:58.000Z","updated":"2022-02-27T11:30:00.838Z","comments":true,"path":"2018/11/23/使用静态内部类实现单例/","link":"","permalink":"https://gxstax.github.io/2018/11/23/%E4%BD%BF%E7%94%A8%E9%9D%99%E6%80%81%E5%86%85%E9%83%A8%E7%B1%BB%E5%AE%9E%E7%8E%B0%E5%8D%95%E4%BE%8B/","excerpt":"","text":"单例模式之利用静态类实现单例 利用静态类在jvm内存模型中存储在静态块且只有一个实例的属性，可以轻松实现单例，保证了线程的安全性； 具体代码如下 1234567891011121314151617181920212223242526package com.ant.innerclass; /** * @author Ant gxstax@163.com * @ClassName: HolderSingleton * @Description: 静态内部类实现单例 * @datetime 2018/11/23 14:11 * @Version 1.0 */public class HolderSingleton &#123; private HolderSingleton() &#123; &#125; public static final class Holder &#123; private static final HolderSingleton instance = new HolderSingleton(); &#125; public static HolderSingleton getInstance () &#123; return Holder.instance; &#125; public static void main(String[] args) &#123; System.out.println(HolderSingleton.getInstance()); &#125;&#125;","categories":[{"name":"java","slug":"java","permalink":"https://gxstax.github.io/categories/java/"}],"tags":[{"name":"java","slug":"java","permalink":"https://gxstax.github.io/tags/java/"}]},{"title":"项目发布流程","slug":"项目发布流程","date":"2017-02-28T02:24:25.000Z","updated":"2022-03-01T03:16:40.033Z","comments":true,"path":"2017/02/28/项目发布流程/","link":"","permalink":"https://gxstax.github.io/2017/02/28/%E9%A1%B9%E7%9B%AE%E5%8F%91%E5%B8%83%E6%B5%81%E7%A8%8B/","excerpt":"","text":"博客发布流程 新增 categories 分类页面 新建页面 1$ hexo new page k8s 配置 打开 blog/source/k8s/index.md，默认是下列内容： 1234---title: 分类date: 2018-10-22 14:25:08--- 修改为： 123456---title: 分类date: 2018-10-22 14:25:08type: &quot;categories&quot;comments: false--- 新建文章 1$ hexo new &quot;k8s集群搭建&quot; 打开 blog/source/_posts/k8s集群搭建.md, 默认头部信息如下: 12345---title: k8s集群搭建date: 2018-10-22 23:03:42tags:--- 修改为 12345678910111213---title: k8s集群搭建comments: truedate: 2018-10-22 23:03:42updated: 2019-10-22 23:03:42desc: 云服务器k8s集群搭建categories: - k8stags: [k8s]keywords: k8s, cloudnative---## k8s 集群搭建具体的文章内容.......... 重启服务 123456# 如果修改了 _config.theme.yml 注意执行 npm run build$ npm run build$ npm run server# 如果未修改过，执行下面命令$ hexo g &amp;&amp; hexo s 友链​ 友链与主题分离，数据存放在数据文件夹的links.yml中​ 例子: 12345678910# links马以: link: https://www.ant.top avatar: https://www.ant.top/images/avatar.jpg desc: 马以Ant: link: https://www.ant.top avatar: https://www.ant.top/images/avatar.jpg desc: Ant 本地搜索需要安装hexo-generator-json-content 1$ npm i -S hexo-generator-json-content 主题配置 menu 是否显示左侧 header 中的菜单，如果不需要可以注释掉。 menu_icons enable左侧菜单是否显示图标，如不需要可以设置成false其他配置项的值为iconfont的class。一般不需要更改，如果你需要新增图标可以提 Issue 或者更改图标可以更改主题的src/css/iconfont.css。图标来自阿里的 iconfont.cn。 site favicon 站点 favicon，相对source或主题根目录下的source例如/images.fvicon.ico相当于在source/images/favicon.ico中找。 site_verfication Google 或 Baidu 提供的 HTML meta 验证。形如 1&lt;meta name=&quot;google-site-verification&quot; content=&quot;your verification string&quot;&gt; 将 content 里的内容粘贴到对应的属性中。 google_analytics 在 Google Analytics 找到跟踪 ID(一般是以 UA- 开头)填入。留空不启用。 pagination prev， next 是否总是显示，默认为 true。仅当多于一页时有效。 comment type 选择启用哪一种评论系统。留空则不启用。你可以通过front-matter的comment: boolean控制具体一篇 post 是否开启评论。默认开启。 github username GitHub username postCount enable 是否启用。需要安装相关的插件 1$ npm i --save hexo-wordcount wordocunt 是否显示文章字数统计 min2read 是否显示阅读时长预计 toc TOC 全局开关你可以通过front-matter的toc: boolean控制是否具体一篇 post 是否开启 toc。默认开启。 fancybox 是否开启基于LightGallery图片 FancyBox 效果。默认开启。 license Copyright 显示的 HTML 片段。注释掉则不显示Copyright footer custom 自定义 Footer 的 HTML 片段。注释掉则不显示。 具体例子可参考 DemoDemo 源文件 Source profile enable 是否显示 profile效果可以参考 DemoDemo 源文件 Source social links Footer 显示的社交联系图标和链接。如需要添加图标可以提 Issue links About 页面侧栏显示的链接 labels About 页面侧栏显示的 Labels skills About 页面侧栏显示的 Skills works About 页面侧栏显示的个人项目 widgets 侧栏显示的 widget， 注释则关闭。 show_count 侧栏的 tag， archive，category widget 中是否显示文章数量 cdn 用到的 CDN 地址，如果你不知道是什么就不要改动。","categories":[],"tags":[]},{"title":"Hello World","slug":"hello-world","date":"2016-12-28T02:24:25.000Z","updated":"2022-03-01T03:17:20.780Z","comments":true,"path":"2016/12/28/hello-world/","link":"","permalink":"https://gxstax.github.io/2016/12/28/hello-world/","excerpt":"","text":"Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new &quot;My New Post&quot; More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment","categories":[],"tags":[]}],"categories":[{"name":"云原生","slug":"云原生","permalink":"https://gxstax.github.io/categories/%E4%BA%91%E5%8E%9F%E7%94%9F/"},{"name":"k8s","slug":"云原生/k8s","permalink":"https://gxstax.github.io/categories/%E4%BA%91%E5%8E%9F%E7%94%9F/k8s/"},{"name":"middleware","slug":"middleware","permalink":"https://gxstax.github.io/categories/middleware/"},{"name":"db","slug":"db","permalink":"https://gxstax.github.io/categories/db/"},{"name":"network","slug":"network","permalink":"https://gxstax.github.io/categories/network/"},{"name":"linuxProgram","slug":"linuxProgram","permalink":"https://gxstax.github.io/categories/linuxProgram/"},{"name":"linux","slug":"linux","permalink":"https://gxstax.github.io/categories/linux/"},{"name":"jvm","slug":"jvm","permalink":"https://gxstax.github.io/categories/jvm/"},{"name":"java","slug":"java","permalink":"https://gxstax.github.io/categories/java/"}],"tags":[{"name":"k8s","slug":"k8s","permalink":"https://gxstax.github.io/tags/k8s/"},{"name":"middleware","slug":"middleware","permalink":"https://gxstax.github.io/tags/middleware/"},{"name":"db","slug":"db","permalink":"https://gxstax.github.io/tags/db/"},{"name":"network","slug":"network","permalink":"https://gxstax.github.io/tags/network/"},{"name":"linuxProgram","slug":"linuxProgram","permalink":"https://gxstax.github.io/tags/linuxProgram/"},{"name":"linux","slug":"linux","permalink":"https://gxstax.github.io/tags/linux/"},{"name":"jvm","slug":"jvm","permalink":"https://gxstax.github.io/tags/jvm/"},{"name":"java","slug":"java","permalink":"https://gxstax.github.io/tags/java/"}]}